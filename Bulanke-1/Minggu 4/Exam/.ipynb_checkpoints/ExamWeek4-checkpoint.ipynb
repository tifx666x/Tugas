{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "306269ee-02a6-45a8-a664-08e71aade0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                              review sentiment\n",
       " 0  One of the other reviewers has mentioned that ...  positive\n",
       " 1  A wonderful little production. <br /><br />The...  positive\n",
       " 2  I thought this was a wonderful way to spend ti...  positive\n",
       " 3  Basically there's a family where a little boy ...  negative\n",
       " 4  Petter Mattei's \"Love in the Time of Money\" is...  positive,\n",
       " None,\n",
       "                                                    review sentiment\n",
       " count                                               50000     50000\n",
       " unique                                              49582         2\n",
       " top     Loved today's show!!! It was a variety and not...  positive\n",
       " freq                                                    5     25000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reviews_dataset_path = 'IMDB Dataset.csv'\n",
    "\n",
    "# Load Bahasa Indonesia reviews dataset\n",
    "df = pd.read_csv(reviews_dataset_path)\n",
    "\n",
    "\n",
    "df_head = df.head()\n",
    "\n",
    "df_info = df.info()\n",
    "df_desc = df.describe()\n",
    "\n",
    "df_head, df_info,df_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "869f511d-ae9c-44ea-b3d9-0bf9b4f8bb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = text.split()\n",
    "    filtered_sentence = ''\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            filtered_sentence = filtered_sentence + word + ' '\n",
    "    return filtered_sentence\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    # get rid of urls\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    # get rid of non words and extra spaces\n",
    "    text = re.sub('\\\\W', ' ', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = re.sub('^ ', '', text)\n",
    "    text = re.sub(' $', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    table = str.maketrans('','',string.punctuation)\n",
    "    words = text.split()\n",
    "    filtered_sentence = ''\n",
    "    for word in words:\n",
    "        word = word.translate(table)\n",
    "        filtered_sentence = filtered_sentence + word + ' '\n",
    "    return filtered_sentence\n",
    "\n",
    "def stemming(text):\n",
    "    ps = PorterStemmer()\n",
    "    words = text.split()\n",
    "    filtered_sentence = ''\n",
    "    for word in words:\n",
    "        word = ps.stem(word)\n",
    "        filtered_sentence = filtered_sentence + word + ' '\n",
    "    return filtered_sentence\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(',',' , ')\n",
    "    text = text.replace('.',' . ')\n",
    "    text = text.replace('/',' / ')\n",
    "    text = text.replace('@',' @ ')\n",
    "    text = text.replace('#',' # ')\n",
    "    text = text.replace('?',' ? ')\n",
    "    text = normalize_text(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = stemming(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72d2014d-2e97-4ae7-9d78-a9ebbdd86c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"review\"]\n",
    "y = df['sentiment']\n",
    "\n",
    "one = OneHotEncoder()\n",
    "y = one.fit_transform(np.asarray(y).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60288c61-73b2-416e-85cc-dd63260e30db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                   y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42,\n",
    "                                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ac1806b-3e57-42e9-8999-92a60619a0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important properties\n",
    "vocab_size = 10000\n",
    "max_length = 50\n",
    "\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd76123-da55-4fda-90d7-cdd0218f9d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tokenizer and fit on texts\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
